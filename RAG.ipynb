{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading Faker-36.1.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faker) (2024.1)\n",
      "Downloading Faker-36.1.1-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 15.3 MB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-36.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "NUM_EMPLOYEES = 1_000_000  # Adjust to increase data volume\n",
    "BATCH_SIZE = 10_000        # Number of rows per batch\n",
    "DEPARTMENTS = ['Sales', 'Engineering', 'HR', 'Marketing', 'Finance', 'Operations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_big_database(db_name='big_database.db'):\n",
    "    with sqlite3.connect(db_name) as conn:\n",
    "        c = conn.cursor()\n",
    "        # Create employees table\n",
    "        c.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS employees (\n",
    "                employee_id INTEGER PRIMARY KEY,\n",
    "                name TEXT,\n",
    "                department TEXT,\n",
    "                salary REAL,\n",
    "                hire_date TEXT\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()  # Explicit commit after table creation\n",
    "\n",
    "        print(\"Generating employee data...\")\n",
    "        # Insert data in batches\n",
    "        for batch_start in range(1, NUM_EMPLOYEES + 1, BATCH_SIZE):\n",
    "            batch = []\n",
    "            for i in range(batch_start, min(batch_start + BATCH_SIZE, NUM_EMPLOYEES + 1)):\n",
    "                name = fake.name()\n",
    "                department = random.choice(DEPARTMENTS)\n",
    "                salary = round(random.uniform(30000, 200000), 2)\n",
    "                hire_date = fake.date_between(start_date='-20y', end_date='today').isoformat()\n",
    "                batch.append((i, name, department, salary, hire_date))\n",
    "            c.executemany('INSERT INTO employees VALUES (?, ?, ?, ?, ?)', batch)\n",
    "            # Commit is automatic on exiting the 'with' block, but we can also call commit here if desired.\n",
    "            conn.commit()\n",
    "            print(f\"Inserted records {batch_start} to {batch_start + len(batch) - 1}\")\n",
    "    print(\"Big database creation complete and committed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(big_db='big_database.db'):\n",
    "    with sqlite3.connect(big_db) as conn:\n",
    "        c = conn.cursor()\n",
    "        # Overall aggregates\n",
    "        c.execute('SELECT COUNT(*), MIN(salary), MAX(salary), SUM(salary) FROM employees')\n",
    "        total_employees, min_salary, max_salary, total_expenditure = c.fetchone()\n",
    "        # Aggregates by department\n",
    "        c.execute('SELECT department, COUNT(*) FROM employees GROUP BY department')\n",
    "        dept_counts = c.fetchall()\n",
    "    return {\n",
    "        'total_employees': total_employees,\n",
    "        'min_salary': min_salary,\n",
    "        'max_salary': max_salary,\n",
    "        'total_expenditure': total_expenditure,\n",
    "        'department_counts': dept_counts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregated_database(aggregates, agg_db='aggregated_database.db'):\n",
    "    with sqlite3.connect(agg_db) as conn:\n",
    "        c = conn.cursor()\n",
    "        # Create tables for aggregates\n",
    "        c.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS company_summary (\n",
    "                metric TEXT PRIMARY KEY,\n",
    "                value TEXT\n",
    "            )\n",
    "        ''')\n",
    "        c.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS department_counts (\n",
    "                department TEXT PRIMARY KEY,\n",
    "                employee_count INTEGER\n",
    "            )\n",
    "        ''')\n",
    "        # Insert overall metrics\n",
    "        summary_data = [\n",
    "            ('total_employees', str(aggregates['total_employees'])),\n",
    "            ('min_salary', f\"{aggregates['min_salary']:.2f}\"),\n",
    "            ('max_salary', f\"{aggregates['max_salary']:.2f}\"),\n",
    "            ('total_expenditure', f\"{aggregates['total_expenditure']:.2f}\")\n",
    "        ]\n",
    "        c.executemany('INSERT OR REPLACE INTO company_summary VALUES (?, ?)', summary_data)\n",
    "        # Insert department counts\n",
    "        c.executemany('INSERT OR REPLACE INTO department_counts VALUES (?, ?)', aggregates['department_counts'])\n",
    "        conn.commit()\n",
    "    print(\"Aggregated database created and committed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting database generation...\n",
      "Generating employee data...\n",
      "Inserted records 1 to 10000\n",
      "Inserted records 10001 to 20000\n",
      "Inserted records 20001 to 30000\n",
      "Inserted records 30001 to 40000\n",
      "Inserted records 40001 to 50000\n",
      "Inserted records 50001 to 60000\n",
      "Inserted records 60001 to 70000\n",
      "Inserted records 70001 to 80000\n",
      "Inserted records 80001 to 90000\n",
      "Inserted records 90001 to 100000\n",
      "Inserted records 100001 to 110000\n",
      "Inserted records 110001 to 120000\n",
      "Inserted records 120001 to 130000\n",
      "Inserted records 130001 to 140000\n",
      "Inserted records 140001 to 150000\n",
      "Inserted records 150001 to 160000\n",
      "Inserted records 160001 to 170000\n",
      "Inserted records 170001 to 180000\n",
      "Inserted records 180001 to 190000\n",
      "Inserted records 190001 to 200000\n",
      "Inserted records 200001 to 210000\n",
      "Inserted records 210001 to 220000\n",
      "Inserted records 220001 to 230000\n",
      "Inserted records 230001 to 240000\n",
      "Inserted records 240001 to 250000\n",
      "Inserted records 250001 to 260000\n",
      "Inserted records 260001 to 270000\n",
      "Inserted records 270001 to 280000\n",
      "Inserted records 280001 to 290000\n",
      "Inserted records 290001 to 300000\n",
      "Inserted records 300001 to 310000\n",
      "Inserted records 310001 to 320000\n",
      "Inserted records 320001 to 330000\n",
      "Inserted records 330001 to 340000\n",
      "Inserted records 340001 to 350000\n",
      "Inserted records 350001 to 360000\n",
      "Inserted records 360001 to 370000\n",
      "Inserted records 370001 to 380000\n",
      "Inserted records 380001 to 390000\n",
      "Inserted records 390001 to 400000\n",
      "Inserted records 400001 to 410000\n",
      "Inserted records 410001 to 420000\n",
      "Inserted records 420001 to 430000\n",
      "Inserted records 430001 to 440000\n",
      "Inserted records 440001 to 450000\n",
      "Inserted records 450001 to 460000\n",
      "Inserted records 460001 to 470000\n",
      "Inserted records 470001 to 480000\n",
      "Inserted records 480001 to 490000\n",
      "Inserted records 490001 to 500000\n",
      "Inserted records 500001 to 510000\n",
      "Inserted records 510001 to 520000\n",
      "Inserted records 520001 to 530000\n",
      "Inserted records 530001 to 540000\n",
      "Inserted records 540001 to 550000\n",
      "Inserted records 550001 to 560000\n",
      "Inserted records 560001 to 570000\n",
      "Inserted records 570001 to 580000\n",
      "Inserted records 580001 to 590000\n",
      "Inserted records 590001 to 600000\n",
      "Inserted records 600001 to 610000\n",
      "Inserted records 610001 to 620000\n",
      "Inserted records 620001 to 630000\n",
      "Inserted records 630001 to 640000\n",
      "Inserted records 640001 to 650000\n",
      "Inserted records 650001 to 660000\n",
      "Inserted records 660001 to 670000\n",
      "Inserted records 670001 to 680000\n",
      "Inserted records 680001 to 690000\n",
      "Inserted records 690001 to 700000\n",
      "Inserted records 700001 to 710000\n",
      "Inserted records 710001 to 720000\n",
      "Inserted records 720001 to 730000\n",
      "Inserted records 730001 to 740000\n",
      "Inserted records 740001 to 750000\n",
      "Inserted records 750001 to 760000\n",
      "Inserted records 760001 to 770000\n",
      "Inserted records 770001 to 780000\n",
      "Inserted records 780001 to 790000\n",
      "Inserted records 790001 to 800000\n",
      "Inserted records 800001 to 810000\n",
      "Inserted records 810001 to 820000\n",
      "Inserted records 820001 to 830000\n",
      "Inserted records 830001 to 840000\n",
      "Inserted records 840001 to 850000\n",
      "Inserted records 850001 to 860000\n",
      "Inserted records 860001 to 870000\n",
      "Inserted records 870001 to 880000\n",
      "Inserted records 880001 to 890000\n",
      "Inserted records 890001 to 900000\n",
      "Inserted records 900001 to 910000\n",
      "Inserted records 910001 to 920000\n",
      "Inserted records 920001 to 930000\n",
      "Inserted records 930001 to 940000\n",
      "Inserted records 940001 to 950000\n",
      "Inserted records 950001 to 960000\n",
      "Inserted records 960001 to 970000\n",
      "Inserted records 970001 to 980000\n",
      "Inserted records 980001 to 990000\n",
      "Inserted records 990001 to 1000000\n",
      "Big database creation complete and committed.\n",
      "Aggregates computed:\n",
      "  Total employees: 1000000\n",
      "  Min salary: $30000.17\n",
      "  Max salary: $199999.95\n",
      "  Total expenditure: $115131962290.34\n",
      "    Engineering: 166571\n",
      "    Finance: 167205\n",
      "    HR: 166336\n",
      "    Marketing: 166718\n",
      "    Operations: 166479\n",
      "    Sales: 166691\n",
      "Aggregated database created and committed.\n",
      "Process completed in: 0:04:11.553225\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time = datetime.now()\n",
    "    print(\"Starting database generation...\")\n",
    "\n",
    "    # Create and commit the big database automatically.\n",
    "    create_big_database()\n",
    "\n",
    "    # Compute aggregates from the big database.\n",
    "    aggregates = aggregate_data()\n",
    "    print(\"Aggregates computed:\")\n",
    "    print(f\"  Total employees: {aggregates['total_employees']}\")\n",
    "    print(f\"  Min salary: ${aggregates['min_salary']:.2f}\")\n",
    "    print(f\"  Max salary: ${aggregates['max_salary']:.2f}\")\n",
    "    print(f\"  Total expenditure: ${aggregates['total_expenditure']:.2f}\")\n",
    "    for dept, count in aggregates['department_counts']:\n",
    "        print(f\"    {dept}: {count}\")\n",
    "\n",
    "    # Create the aggregated database automatically.\n",
    "    create_aggregated_database(aggregates)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(\"Process completed in:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API of LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_04zBDMfz7ZCc0IN8eMD7KCHLh8QuSkN0kngpN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"NexaAIDev/DeepSeek-R1-Distill-Llama-8B-NexaQuant\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"NexaAIDev/DeepSeek-R1-Distill-Llama-8B-NexaQuant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_to_sql_local(human_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses a locally loaded language model to convert a human language query into SQL.\n",
    "    The database schema is assumed to be:\n",
    "      - company_summary(metric TEXT, value TEXT)\n",
    "      - department_counts(department TEXT, employee_count INTEGER)\n",
    "    \"\"\"\n",
    "    # Build a prompt that gives context to the model.\n",
    "    prompt = (\n",
    "        \"You are an expert SQL generator. Convert the following human language question into a SQL query for a SQLite database. \\n\"\n",
    "        \"The database has two tables:\\n\"\n",
    "        \"1. company_summary with columns: metric (TEXT), value (TEXT)\\n\"\n",
    "        \"2. department_counts with columns: department (TEXT), employee_count (INTEGER)\\n\\n\"\n",
    "        f\"Question: \\\"{human_query}\\\"\\n\\nSQL Query:\"\n",
    "    )\n",
    "    \n",
    "    # Generate output text. You might need to experiment with parameters.\n",
    "    output = generator(prompt, max_length=150, num_return_sequences=1, temperature=0.0)\n",
    "    \n",
    "    # Extract generated text from the output\n",
    "    generated_text = output[0]['generated_text']\n",
    "    \n",
    "    # Try to extract the SQL query by removing the prompt part.\n",
    "    sql_query = generated_text.replace(prompt, \"\").strip()\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_query(db_path: str, query: str):\n",
    "    \"\"\"\n",
    "    Executes the provided SQL query on the given SQLite database and returns the results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(query)\n",
    "            results = cursor.fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Welcome! Please enter your question in plain English (no SQL required):\")\n",
    "    human_query = input(\"Question: \")\n",
    "\n",
    "    # Convert human language query to SQL using the local model.\n",
    "    sql_query = human_to_sql_local(human_query)\n",
    "    print(\"\\nGenerated SQL query:\")\n",
    "    print(sql_query)\n",
    "\n",
    "    # Execute the SQL query on the aggregated database.\n",
    "    results = run_sql_query(\"aggregated_database.db\", sql_query)\n",
    "    \n",
    "    print(\"\\nQuery Results:\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
